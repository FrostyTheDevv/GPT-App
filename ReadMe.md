# ğŸ§  my_local_gpt

A from-scratch GPT-style language model implementation in Python.

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/Framework-PyTorch-red)
![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)

---

## ğŸ“Œ Overview

This project provides:

- âœ… Byte-Pair Encoding (BPE) tokenizer  
- âœ… GPT-style Transformer decoder in PyTorch  
- âœ… Training pipeline with:
  - Mixed-precision (AMP)
  - Multi-GPU support
  - Gradient accumulation
  - One-Cycle LR schedule
  - TensorBoard logging
  - Checkpointing
- âœ… CLI inference script (`generate.py`) for text generation  
- âœ… Guidelines for FastAPI or Discord bot integration  

---

## ğŸ“ Project Layout
my_local_gpt/
â”œâ”€â”€ data/
â”‚ â””â”€â”€ corpus.txt # Raw text data, one line per example
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ tokenizer.pt # Saved BPE tokenizer (encoder & decoder)
â”‚ â”œâ”€â”€ tokens.pt # Cached token IDs (optional)
â”‚ â”œâ”€â”€ ckpt_step_*.pt # Training checkpoints
â”‚ â””â”€â”€ final_model.pt # Final model weights
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ tokenizer.py # BPETokenizer implementation
â”‚ â”œâ”€â”€ model.py # GPT model definition
â”‚ â””â”€â”€ generate.py # CLI for text generation
â”œâ”€â”€ training/
â”‚ â”œâ”€â”€ build_tokenizer.py # Script to build BPE tokenizer
â”‚ â””â”€â”€ train.py # Full-scale training pipeline
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .gitignore # Git ignore rules
â”œâ”€â”€ LICENSE # Open-source license
â”œâ”€â”€ TOS.md # Terms of Service
â””â”€â”€ README.md # This file

---

## ğŸ§ª Installation

1. **Clone the repository**

```bash
git clone https://github.com/YOUR_USERNAME/my_local_gpt.git
cd my_local_gpt
```

ğŸ§± Building the Tokenizer
```bash
python training/build_tokenizer.py \
  --input data/corpus.txt \
  --vocab_size 30000 \
  --output models/tokenizer.pt
  ```

ğŸ‹ï¸â€â™€ï¸ Training the Model
  ```bash
  python training/train.py \
  --corpus data/corpus.txt \
  --tokenizer models/tokenizer.pt \
  --vocab_size 30000 \
  --model_size 512 \
  --block_size 1024 \
  --batch_size 8 \
  --accum_steps 4 \
  --lr 5e-4 \
  --epochs 5 \
  --save_steps 1000 \
  --out_dir models
   ```

âœ¨ Generating Text
```bash
python src/generate.py "Your prompt here"
 ```

